name: Build and Upload Artifacts

# Added these to use JWT token to connect with AWS
permissions:
  id-token: write   # This is required for requesting the JWT
  contents: read    # This is required for actions/checkout

on:
  workflow_call:
    inputs:
      env:
        default: "${{ vars.RUNS_ON }}"
        type: string
      container:
        type: string
      pre-steps-script:
        type: string
        description: 'Script to run before any other steps (extremely basic dependency needs only)'
      ref:
        type: string
        description: 'RediSearch reference to checkout (defaults to the ref of the triggering event)'
      sha:
        type: string
        description: 'Optional: SHA to checkout. If not provided, `ref` will be used'
      redis-ref:
        type: string

env:
  REF: ${{ inputs.sha || inputs.ref || github.sha }}  # Define fallbacks for ref to checkout
  BRANCH: ${{ inputs.ref || github.ref_name }}        # Define "branch" name for pack name (used in `make pack`)
  BOOST_VERSION: ${{ vars.BOOST_VERSION }}
  AWS_ACCESS_KEY_ID: ${{ secrets.ARTIFACT_UPLOAD_AWS_ACCESS_KEY_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.ARTIFACT_UPLOAD_AWS_SECRET_ACCESS_KEY }}
  AWS_REGION: ${{ vars.ARTIFACT_UPLOAD_AWS_REGION }}

jobs:
  build:
    name: Build ${{ inputs.container || inputs.env }}
    runs-on: ${{ inputs.env }}
    container: ${{ inputs.container || null }}
    defaults:
      run:
        shell: bash -l -eo pipefail {0}
    env:
      VERBOSE: 1 # For logging
      RELEASE: 0 # We build snapshots. This variable is used in the pack name (see `make pack`)
      # Build command
      BUILD_CMD: echo '::group::Build' && make build VERBOSE= GIT_BRANCH=$BRANCH && echo '::endgroup::'
    steps:
      # Setup
      - name: Pre-steps Dependencies
        if: inputs.pre-steps-script
        shell: bash -l -eo pipefail {0}
        run: ${{ inputs.pre-steps-script }}
      - name: Pre-steps Dependencies (Non-Alpine)
        if: inputs.pre-steps-script && inputs.container != 'alpine:3'
        run: ${{ inputs.pre-steps-script }}
      - name: Enable dynamic linking to C runtime in Alpine
        if: inputs.container == 'alpine:3'
        run: echo RUST_DYN_CRT=1 >> $GITHUB_ENV

      - name: Get Installation Mode
        id: mode
        run: |
          [[ -z "${{ inputs.container }}" ]] && echo "mode=sudo" >> $GITHUB_OUTPUT || echo "mode=" >> $GITHUB_OUTPUT
      - name: Check if node20 is Supported
        id: node20 # TODO: Remove this when node20 is supported on all platforms, or when we drop support for theses platforms
        run: |
          for platform in ubuntu:bionic amazonlinux:2 alpine:3; do
            if [[ "${{ inputs.container }}" == "$platform" ]]; then
              echo "supported=false" >> $GITHUB_OUTPUT
              exit 0
            fi
          done
          echo "supported=true" >> $GITHUB_OUTPUT
      - name: Deps checkout (node20)
        if: steps.node20.outputs.supported == 'true'
        uses: actions/checkout@v4
        with:
          path: setup
          ref: ${{ env.REF }}
          sparse-checkout-cone-mode: false
          sparse-checkout: |
            .install
            tests/pytests/requirements.txt
      - name: Deps checkout (node20 not supported)
        if: steps.node20.outputs.supported == 'false'
        run: |
          # Execute the logic based on the detected platform
          echo "Detected platform: ${{ inputs.container }}"
          case "${{ inputs.container }}" in
            ubuntu:bionic | amazonlinux:2 | alpine:3)
              echo "Installing prerequisites for ${{ inputs.container }}..."

              # Install git (platform-specific package management)
              case "${{ inputs.container }}" in
                ubuntu:bionic)
                  apt update
                  apt install -y git
                  ;;
                amazonlinux:2)
                  yum update -y
                  yum install -y git
                  ;;
                alpine:3)
                  apk update
                  apk add --no-cache git
                  ;;
              esac

              # Configure the safe directory
              git config --global --add safe.directory /__w/${{ github.repository }}

              # Checkout
              REPO_URL="https://github.com/${{ github.repository }}.git"

              # Initialize a Git repository
              git init
              git remote add origin "$REPO_URL"

              # Fetch and checkout ref
              git fetch origin "${{ github.ref }}" || {
                echo "Failed to fetch ref: '${{ github.ref }}'";
                exit 1;
              }
              git checkout FETCH_HEAD  # Check out the fetched ref

              # Update submodules
              git submodule update --init --recursive
              ;;
            *)
              echo "Unsupported platform: '${{ inputs.container }}'"
              exit 1
              ;;
          esac
      - name: Setup specific (node20)
        if: steps.node20.outputs.supported == 'true'
        working-directory: setup/.install
        run: |
          ./install_script.sh ${{ steps.mode.outputs.mode }}
      - name: Setup specific (node20 not supported)
        if: steps.node20.outputs.supported == 'false'
        working-directory: .install
        run: |
          ./install_script.sh ${{ steps.mode.outputs.mode }}
      - name: Install aws cli (node20)
        if: steps.node20.outputs.supported == 'true'
        working-directory: setup/.install
        run: ./install_aws.sh ${{ steps.mode.outputs.mode }}
      - name: Install aws cli (node20 not supported)
        if: steps.node20.outputs.supported == 'false'
        working-directory: .install
        run: ./install_aws.sh ${{ steps.mode.outputs.mode }}
      - name: Full checkout (node20)
        if: steps.node20.outputs.supported == 'true'
        uses: actions/checkout@v4
        with:
          submodules: recursive
          ref: ${{ env.REF }}
      - name: Full checkout (node20 not supported)
        if: steps.node20.outputs.supported == 'false'
        run: echo "Done already earlier."
      - name: Setup common
        run: .install/test_deps/common_installations.sh ${{ steps.mode.outputs.mode }}
      - name: install build artifacts req
        run: pip install -q -r .install/build_package_requirments.txt

      - name: Install Boost
        working-directory: .install
        run: ./install_boost.sh ${{ env.BOOST_VERSION }} ${{ steps.mode.outputs.mode }}

      # Get Redis
      - name: Get Redis (node20)
        if: steps.node20.outputs.supported == 'true'
        uses: actions/checkout@v4
        with:
          repository: redis/redis
          ref: ${{ inputs.redis-ref }}
          path: redis
      - name: Get Redis (node20 not supported)
        if: steps.node20.outputs.supported == 'false'
        run: |
            REPO_URL="https://github.com/redis/redis.git"
            DEST_DIR="redis"  # Directory to clone into

            # Clone the repository (shallow clone without tags)
            git clone $REPO_URL $DEST_DIR
            cd $DEST_DIR

            # Checkout the REF
            git fetch origin ${{ inputs.redis-ref }}
            git checkout ${{ inputs.redis-ref }}
      - name: Build Redis
        working-directory: redis
        run: ${{ steps.mode.outputs.mode }} make install

      # Build & Pack
      - name: Build and Pack RediSearch OSS
        env:
          COORD: oss
        run: ${{ env.BUILD_CMD }} && make pack
      - name: Build and Pack RediSearch Lite
        env:
          LITE: 1
        run: ${{ env.BUILD_CMD }} && make pack
      - name: Build and Pack RediSearch Enterprise
        env:
          COORD: rlec
          MAX_WORKER_THREADS: ${{ vars.MAX_WORKER_THREADS }}
        run: ${{ env.BUILD_CMD }} && make pack

      # Upload
      - name: Configure AWS Credentials Using Role (node20)
        if: vars.USE_AWS_ROLE == 'true' && steps.node20.outputs.supported == 'true'
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ vars.ARTIFACT_UPLOAD_AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ vars.ARTIFACT_UPLOAD_AWS_REGION }}
      - name: Configure AWS Credentials Using Role (node20 not supported)
        if: vars.USE_AWS_ROLE == 'true' && steps.node20.outputs.supported == 'false'
        run: |
          # Variables from the workflow
          ROLE_ARN="${{ vars.ARTIFACT_UPLOAD_AWS_ROLE_TO_ASSUME }}"
          AWS_REGION="${{ vars.ARTIFACT_UPLOAD_AWS_REGION }}"
          SESSION_NAME="github-actions-session"

          # Assume the AWS role and configure temporary credentials
          ASSUME_ROLE_OUTPUT=$(aws sts assume-role --role-arn "$ROLE_ARN" --role-session-name "$SESSION_NAME" --region "$AWS_REGION")
          if [ $? -ne 0 ]; then
            echo "Failed to assume AWS role" && exit 1
          fi

          echo "AWS credentials configured successfully."
      - name: Configure AWS Credentials Using Keys (node20)
        if: vars.USE_AWS_ROLE == 'false' && steps.node20.outputs.supported == 'true'
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.ARTIFACT_UPLOAD_AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.ARTIFACT_UPLOAD_AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ vars.ARTIFACT_UPLOAD_AWS_REGION }}
      - name: Configure AWS Credentials Using Keys (node20 not supported)
        if: vars.USE_AWS_ROLE == 'false' && steps.node20.outputs.supported == 'false'
        run: |
          # Variables from the workflow
          AWS_ACCESS_KEY_ID="${{ secrets.ARTIFACT_UPLOAD_AWS_ACCESS_KEY_ID }}"
          AWS_SECRET_ACCESS_KEY="${{ secrets.ARTIFACT_UPLOAD_AWS_SECRET_ACCESS_KEY }}"
          AWS_REGION="${{ vars.ARTIFACT_UPLOAD_AWS_REGION }}"

          # Check if the required environment variables are set
          if [ -z "$AWS_ACCESS_KEY_ID" ] || [ -z "$AWS_SECRET_ACCESS_KEY" ] || [ -z "$AWS_REGION" ]; then
            echo "Missing AWS credentials or region configuration."
            exit 1
          fi

          # Configure AWS CLI with provided credentials and region
          echo "Configuring AWS CLI with access keys..."
          aws configure set aws_access_key_id "$AWS_ACCESS_KEY_ID"
          aws configure set aws_secret_access_key "$AWS_SECRET_ACCESS_KEY"
          aws configure set region "$AWS_REGION"

      - name: Upload Artifacts
        run: |
          echo "::group::Uploading artifacts to S3"
          S3_URL="s3://redismodules"
          # Artifact directory with snapshots
          ARTIFACTS_DIR="bin/artifacts/snapshots"
          PLATFORM="${{ runner.os }}-${{ inputs.container || inputs.env }}-$(uname -m)"
          PLATFORM=$(echo "$PLATFORM" | sed 's/:/\-/g') # Replace colons with hyphens
          
          # Upload OSS artifacts
          echo "Uploading redisearch-community artifacts..."
          for file in $ARTIFACTS_DIR/redisearch-community.*${PLATFORM}*.zip; do
            if [[ -f "$file" ]]; then
              aws s3 cp "$file" "${S3_URL}/redisearch-oss/snapshots/" --acl public-read
            fi
          done
          
          # Upload enterprise artifacts
          echo "Uploading redisearch artifacts..."
          for file in $ARTIFACTS_DIR/redisearch.*${PLATFORM}*.zip; do
            if [[ -f "$file" ]]; then
              aws s3 cp "$file" "${S3_URL}/redisearch/snapshots/" --acl public-read
            fi
          done
          
          # Upload light artifacts
          echo "Uploading redisearch-light artifacts..."
          for file in $ARTIFACTS_DIR/redisearch-light.*${PLATFORM}*.zip; do
            if [[ -f "$file" ]]; then
              aws s3 cp "$file" "${S3_URL}/redisearch/snapshots/" --acl public-read
            fi
          done
          
          # List uploads for verification
          echo "Listing uploaded artifacts:"
          aws s3 ls "${S3_URL}/redisearch-oss/snapshots/" | grep "${PLATFORM}"
          aws s3 ls "${S3_URL}/redisearch/snapshots/" | grep "${PLATFORM}"
          
          echo "::endgroup::"
