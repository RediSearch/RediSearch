name: Run a Micro Benchmark Flow

on:
    # Manual trigger
    workflow_dispatch:
      inputs:
        profile_env:
          type: number # for default of 0
        rejson_branch:
          type: string
          default: master
          description: 'branch to use for rejson'
        benchmark_folder: 
          type: string
          default: src/redisearch_rs/trie_bencher
          description: folder containing the benchmark to be run with `cargo bench`
        output_folder:
          type: string
          default: bin/criterion/trie
          description: folder used to store the output of criterion
    
    # For calling from other workflows
    workflow_call:
      inputs:
        profile_env:
          type: number # for default of 0
        rejson_branch:
          type: string
          default: master
          description: 'branch to use for rejson'
        benchmark_folder: 
          type: string
          default: src/redisearch_rs/trie_bencher
          description: folder containing the benchmark to be run with `cargo bench`
        output_folder:
          type: string
          default: bin/criterion/trie
          description: folder used to store the output of criterion

jobs:
  benchmarks:
    runs-on: ubuntu-24.04
    env:
      RUST_BACKTRACE: full
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          submodules: recursive
      - name: Setup specific  # assuming node20 supported
        working-directory: .install
        run: |
          ./install_script.sh ${{ steps.mode.outputs.mode }} sudo
      - name: Setup tests dependencies
        run: |
          .install/test_deps/common_installations.sh ${{ steps.mode.outputs.mode }} sudo
      - name: Install Boost
        working-directory: .install
        run: ./install_boost.sh ${{ env.BOOST_VERSION }} sudo

      - name: Build RediSearch
        run: make build
            PROFILE=${{ inputs.profile_env }}
            SHOW=1
      - name: Prepare automation
        run: |
          ./deps/readies/bin/getpy3
          pip3 install --upgrade pip
          python3 -m pip install -r tests/benchmarks/requirements.txt
          VERSION=1.11.1 sudo ./deps/readies/bin/getterraform
      - name: Prepare ReJSON Module
        run: REJSON_BRANCH=${{ inputs.rejson_branch }} ./tests/deps/setup_rejson.sh
      
      - name: Get Latest Baseline
        uses: actions/download-artifact@v4
        with: 
          name: rust-benchmark-results-master
          path: ${{ inputs.output_folder }}
        continue-on-error: true # Prevent failure if no baseline exists yet
      - name: Check if Baseline Exists
        id: check_baseline
        run: |
          if [ -d ${{ inputs.output_folder }} ]; then
            echo "baseline_exists=true" >> $GITHUB_OUTPUT
          else
            echo "baseline_exists=false" >> $GITHUB_OUTPUT
          fi
      - name: Create output directory if not existing
        run: mkdir -p "${{ inputs.output_folder }}"    
      - name: Run benchmark on PR with baseline from master
        if: github.event_name == 'pull_request' && steps.check_baseline.outputs.baseline_exists == 'true'
        run: ./memory_tracked_command.sh "cargo bench -- --baseline master" 12582912
        working-directory: ${{ inputs.benchmark_folder }}
      - name: Run benchmark on PR without baseline
        if: github.event_name == 'pull_request' && steps.check_baseline.outputs.baseline_exists == 'false'
        run: ./memory_tracked_command.sh "cargo bench" 12582912
        working-directory: ${{ inputs.benchmark_folder }}
      - name: Run benchmark on master
        if: github.ref == 'refs/heads/master' && github.event_name == 'push' && success() 
        run: ./memory_tracked_command.sh "cargo bench -- --save-baseline master" 12582912
        working-directory: ${{ inputs.benchmark_folder }}

      - name: Upload rust baseline benchmarks for master
        if: github.ref == 'refs/heads/master' && github.event_name == 'push' && success() 
        uses: actions/upload-artifact@v4
        with:
          name: "rust-benchmark-results-master"
          path: ${{ inputs.output_folder }}
      - name: Upload benchmarks for PR comparison
        if: github.event_name == 'pull_request'
        uses: actions/upload-artifact@v4
        with:
          name: "rust-benchmark-results-pr-${{ github.event.pull_request.number }}"
          path: ${{ inputs.output_folder }}  